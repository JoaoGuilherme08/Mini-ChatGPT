{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoGuilherme08/Mini-ChatGPT/blob/main/Mini-ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4knibRpAQ06"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g-f7cQmf2Nt"
      },
      "source": [
        "#@markdown **NVIDIA GPU**\n",
        "import subprocess\n",
        "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(sub_p_res)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXWnyarPu3pc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "Fo6-tJmeujo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "0756T2AMu87z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.test.is_gpu_available())"
      ],
      "metadata": {
        "id": "6rTICTivumqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import download texts"
      ],
      "metadata": {
        "id": "OoBrPkXRvH5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "# Download and preprocess the data from the URL\n",
        "response = requests.get(\"https://www.gutenberg.org/files/55/55-0.txt\")\n",
        "wizard_of_oz = response.text"
      ],
      "metadata": {
        "id": "aXk10uIXvF8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_text = \"*** START OF THE PROJECT GUTENBERG EBOOK THE WONDERFUL WIZARD OF OZ ***\"\n",
        "# Find the index where the start_text occurs\n",
        "start_index = wizard_of_oz.find(start_text) + 28\n",
        "\n",
        "# Extract the text after the start_text\n",
        "wizard_of_oz = wizard_of_oz[start_index + len(start_text):]\n",
        "print(wizard_of_oz[:250] + \"...\")"
      ],
      "metadata": {
        "id": "m_Zcx4ClvWIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_text = \"*** END OF THE PROJECT GUTENBERG EBOOK THE WONDERFUL WIZARD OF OZ ***\"\n",
        "\n",
        "# Find the index where the end_text occurs\n",
        "end_index = wizard_of_oz.find(end_text)\n",
        "\n",
        "# Extract the text before the end_text\n",
        "wizard_of_oz = wizard_of_oz[:end_index]\n",
        "\n",
        "# show the final of the text\n",
        "print(wizard_of_oz[-200:])"
      ],
      "metadata": {
        "id": "mLCARogEvbe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "sentences = wizard_of_oz.split(\".\")\n",
        "sentences = [s.strip() for s in sentences if len(s) > 0]\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "WKjNZhSgveqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input-output sequences\n",
        "input_sequences = []\n",
        "for sentence in sentences:\n",
        "    seq = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(seq)):\n",
        "        n_gram_seq = seq[:i+1]\n",
        "        input_sequences.append(n_gram_seq)"
      ],
      "metadata": {
        "id": "U5zNS4MovjvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "max_seq_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n"
      ],
      "metadata": {
        "id": "Nle439PwvmzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split input-output sequences into input (X) and output (y)\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "gg8dNH3-vpqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y to categorical labels\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "IZnJGGOevslw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 100, input_length=max_seq_len-1),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "# Plot the model architecture\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "id": "JIttQHoHvwFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sKwIdh2Dv22S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "11ksT9Div8Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "id": "e76rzH1Gv_Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to generate sentence completion"
      ],
      "metadata": {
        "id": "oVPswp5iwOa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate sentence completion\n",
        "def complete_sentence(model, tokenizer, initial_text, max_length=20):\n",
        "    input_text = initial_text\n",
        "    for _ in range(max_length):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        encoded_text = pad_sequences([encoded_text], maxlen=max_seq_len-1, padding='pre')\n",
        "        predicted_probabilities = model.predict(encoded_text, verbose=0)[0]\n",
        "        predicted_index = tf.argmax(predicted_probabilities, axis=-1).numpy()\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "        input_text += \" \" + predicted_word\n",
        "        if predicted_word == '.':\n",
        "            break\n",
        "    return input_text + \"...\""
      ],
      "metadata": {
        "id": "krG8369SwQGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate a completed sentence"
      ],
      "metadata": {
        "id": "uqgBmpwowVpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a completed sentence\n",
        "completed_sentence = complete_sentence(model, tokenizer, \"Uncle Henry never laughed\", max_length=10)\n",
        "print(completed_sentence)"
      ],
      "metadata": {
        "id": "R1PeABe_wXTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a completed sentence\n",
        "completed_sentence = complete_sentence(model, tokenizer, \"While she stood looking\", max_length=10)\n",
        "print(completed_sentence)"
      ],
      "metadata": {
        "id": "ca68CNG9wbwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a completed sentence\n",
        "completed_sentence = complete_sentence(model, tokenizer, \"The little old woman took the slate from her nose\", max_length=10)\n",
        "print(completed_sentence)"
      ],
      "metadata": {
        "id": "ghdgUghtwcwf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}